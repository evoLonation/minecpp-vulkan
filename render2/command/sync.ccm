export module render.vk.sync;

import "vulkan_config.h";
import render.vk.resource;
import render.vk.device;
import render.vk.tool;
import render.vk.reflections;

import std;
import toy;

export namespace rd::vk {

namespace device_checkers {

auto sync(DeviceCapabilityBuilder& builder) -> bool {
  if (!builder.enableFeature(&VkPhysicalDeviceVulkan13Features::synchronization2)) {
    return false;
  }
  if (!builder.enableFeature(&VkPhysicalDeviceVulkan12Features::timelineSemaphore)) {
    return false;
  }
  return true;
}

} // namespace device_checkers

class TimelineSemaphore : public rs::Semaphore {
public:
  TimelineSemaphore(uint64 initial_value = 0) {
    auto type_info = VkSemaphoreTypeCreateInfo{
      .sType = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO,
      .semaphoreType = VK_SEMAPHORE_TYPE_TIMELINE,
      .initialValue = initial_value,
    };
    VkSemaphoreCreateInfo create_info{
      .sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO,
      .pNext = &type_info,
    };
    rs::Semaphore::operator=(create_info);
    _newest_value = initial_value;
  }
  ~TimelineSemaphore() {
    if (get()) {
      waitIdle();
    }
  }
  TimelineSemaphore(const TimelineSemaphore&) noexcept = delete;
  TimelineSemaphore(TimelineSemaphore&&) noexcept = default;
  auto operator=(const TimelineSemaphore&) noexcept -> TimelineSemaphore& = delete;
  auto operator=(TimelineSemaphore&&) noexcept -> TimelineSemaphore& = default;
  auto getValue() const -> uint64 {
    uint64 value;
    checkVkResult(vkGetSemaphoreCounterValue(Device::getInstance().get(), get(), &value), "");
    return value;
  }

  auto wait(uint64 value, uint64 nano_timeout = std::numeric_limits<uint64>::max()) -> bool {
    return wait(
      std::array{ std::pair<TimelineSemaphore&, uint64>{ *this, value } }, false, nano_timeout
    );
  }

  static auto wait(
    std::span<std::pair<TimelineSemaphore&, uint64> const> semaphores,
    bool                                                   any = false,
    uint64 nano_timeout = std::numeric_limits<uint64>::max()
  ) -> bool {
    auto handles = semaphores | views::transform([](auto& s) { return s.first.get(); }) |
                   ranges::to<std::vector>();
    auto values =
      semaphores | views::transform([](auto& s) { return s.second; }) | ranges::to<std::vector>();
    auto wait_info = VkSemaphoreWaitInfo{
      .sType = VK_STRUCTURE_TYPE_SEMAPHORE_WAIT_INFO,
      .flags = any ? VK_SEMAPHORE_WAIT_ANY_BIT : 0u,
      .semaphoreCount = static_cast<uint32>(semaphores.size()),
      .pSemaphores = handles.data(),
      .pValues = values.data(),
    };
    auto res = checkVkResult(
      vkWaitSemaphores(Device::getInstance(), &wait_info, nano_timeout),
      "wait semaphore",
      { VK_SUCCESS, VK_TIMEOUT }
    );
    if (res == VK_SUCCESS) {
      return true;
    } else {
      return false;
    }
  }

  void signal(uint64 value) {
    auto signal_info = VkSemaphoreSignalInfo{
      .sType = VK_STRUCTURE_TYPE_SEMAPHORE_SIGNAL_INFO,
      .semaphore = get(),
      .value = value,
    };
    checkVkResult(vkSignalSemaphore(Device::getInstance(), &signal_info), "signal semaphore");
    _newest_value = value;
  }

  /**
   * @brief Update the newest and biggest signaled value (no matter pending or not)
   *
   * @param value must bigger than the return value of getNewestValue
   */
  void updateValue(uint64 value) {
    if (value <= _newest_value) {
      toy::throwf(
        "TimelineSemaphore::updateValue: value must bigger than the return value of getNewestValue"
      );
    }
    _newest_value = value;
  }
  auto getNewestValue() const -> uint64 { return _newest_value; }

  auto increaseValue() -> uint64 { return ++_newest_value; }

  auto waitIdle(uint64 nano_timeout = std::numeric_limits<uint64>::max()) -> bool {
    return wait(getNewestValue(), nano_timeout);
  }

private:
  uint64 _newest_value;
};

class TimelineSemaphorePool {
public:
  TimelineSemaphorePool() { _idle_semas.resize(10); }
  auto allocate() -> TimelineSemaphore {
    if (_idle_semas.empty()) {
      workingToIdle();
    } else {
      tryShrink();
    }
    if (_idle_semas.empty()) {
      return TimelineSemaphore{};
    }
    auto ret = std::move(_idle_semas.back());
    _idle_semas.pop_back();
    return ret;
  }

  void recycle(TimelineSemaphore s) { _working_semas.push_back(std::move(s)); }

  void tryShrink() {
    auto shrink_size = 20;
    if (_idle_semas.size() <= shrink_size) {
      return;
    }
    toy::debugf("shrink {} -> {}", _idle_semas.size(), shrink_size);
    _idle_semas.erase(_idle_semas.begin() + shrink_size, _idle_semas.end());
  }

  TimelineSemaphorePool(const TimelineSemaphorePool&) noexcept = delete;
  TimelineSemaphorePool(TimelineSemaphorePool&&) noexcept = delete;
  auto operator=(const TimelineSemaphorePool&) noexcept -> TimelineSemaphorePool& = delete;
  auto operator=(TimelineSemaphorePool&&) noexcept -> TimelineSemaphorePool& = delete;

private:
  std::vector<TimelineSemaphore> _idle_semas;
  std::list<TimelineSemaphore>   _working_semas;

  void workingToIdle() {
    for (auto iter = _working_semas.begin(); iter != _working_semas.end();) {
      if (iter->waitIdle(0)) {
        _idle_semas.push_back(std::move(*iter));
        iter = _working_semas.erase(iter);
      } else {
        iter++;
      }
    }
  }
};

class TimelineSemaphoreRecyclable : public TimelineSemaphore {
public:
  TimelineSemaphoreRecyclable(TimelineSemaphorePool* pool)
    : TimelineSemaphore(pool->allocate()), _pool(pool) {}

  ~TimelineSemaphoreRecyclable() { recycle(); }
  TimelineSemaphoreRecyclable(TimelineSemaphoreRecyclable&& a) noexcept = default;
  auto operator=(TimelineSemaphoreRecyclable&& a) noexcept -> TimelineSemaphoreRecyclable& {
    recycle();
    TimelineSemaphore::operator=(std::move(a));
    _pool = a._pool;
    return *this;
  }

private:
  TimelineSemaphorePool* _pool;

  void recycle() {
    if (get()) {
      _pool->recycle(std::move(*this));
    }
  }
};

auto createSemaphore() -> rs::Semaphore;

class Fence : public rs::Fence {
public:
  Fence() = default;
  Fence(bool signaled);
  /**
   * @brief wait to signaled state
   */
  void wait(bool reset, uint64_t timeout = std::numeric_limits<uint64_t>::max());
  void reset();
  auto isSignaled() -> bool;
};

enum class AccessType {
  WRITE,
  READ,
};

constexpr auto read_accesses = std::array{
  VK_ACCESS_INDIRECT_COMMAND_READ_BIT,
  VK_ACCESS_INDEX_READ_BIT,
  VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT,
  VK_ACCESS_UNIFORM_READ_BIT,
  VK_ACCESS_INPUT_ATTACHMENT_READ_BIT,
  VK_ACCESS_SHADER_READ_BIT,
  VK_ACCESS_SHADER_WRITE_BIT,
  VK_ACCESS_COLOR_ATTACHMENT_READ_BIT,
  VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT,
  VK_ACCESS_TRANSFER_READ_BIT,
  VK_ACCESS_HOST_READ_BIT,
  VK_ACCESS_MEMORY_READ_BIT,
};

constexpr auto write_accesses = std::array{
  VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT, //
  VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT,
  VK_ACCESS_TRANSFER_WRITE_BIT,
  VK_ACCESS_HOST_WRITE_BIT,
  VK_ACCESS_MEMORY_WRITE_BIT,
};
constexpr auto write_access_bits =
  std::reduce(write_accesses.begin(), write_accesses.end(), VkAccessFlags2{}, [](auto a, auto b) {
    return a | b;
  });
constexpr auto read_access_bits =
  std::reduce(read_accesses.begin(), read_accesses.end(), VkAccessFlags2{}, [](auto a, auto b) {
    return a | b;
  });

void checkAccessSupported(VkAccessFlags2 access) {
  toy::throwf(
    (access & (write_access_bits | read_access_bits)) == access,
    "The access contains bit that is not supported"
  );
}
auto extractWriteAccess(VkAccessFlags2 access) -> VkAccessFlags2 {
  checkAccessSupported(access);
  return (access & write_access_bits);
}
/**
 * @brief if exist write bit then return write
 *
 * @param access
 * @return AccessType
 */
auto checkAccessType(VkAccessFlags access) -> AccessType {
  checkAccessSupported(access);
  return extractWriteAccess(access) == 0 ? AccessType::READ : AccessType::WRITE;
}

struct Scope {
  VkPipelineStageFlags2 stage_mask;
  VkAccessFlags2        access_mask;

  auto extractWriteAccess() const -> Scope {
    auto scope = *this;
    scope.access_mask = vk::extractWriteAccess(scope.access_mask);
    return scope;
  }
};

void recordPipelineBarrier(
  VkCommandBuffer                         cmdbuf,
  std::span<const VkMemoryBarrier2>       memory_barriers,
  std::span<const VkBufferMemoryBarrier2> buffer_barriers,
  std::span<const VkImageMemoryBarrier2>  image_barriers
) {
  auto dependency_info = VkDependencyInfo{
    .sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO,
    //  VK_DEPENDENCY_BY_REGION_BIT:
    //  实现可以分区域进行同步(前面写一部分，后面就可以先读一部分)
    .dependencyFlags = 0,
    .memoryBarrierCount = static_cast<uint32>(memory_barriers.size()),
    .pMemoryBarriers = memory_barriers.data(),
    .bufferMemoryBarrierCount = static_cast<uint32>(buffer_barriers.size()),
    .pBufferMemoryBarriers = buffer_barriers.data(),
    .imageMemoryBarrierCount = static_cast<uint32>(image_barriers.size()),
    .pImageMemoryBarriers = image_barriers.data(),
  };
  vkCmdPipelineBarrier2(cmdbuf, &dependency_info);
};

/**
 * @brief In case of ownership transfer that with src_use_stage/access and dst_use_stage/access
 * barrier in src family:
 * - src_stage/access: src_use_stage, src_use_access
 * - dst_stage/access: NONE, 0 (by spec: dst_stage/access are ignored)
 * barrier in dst family:
 * - must wait semaphore, wait stage: TOP
 * - src_stage/access: NONE, 0 (by spec: src_stage/access are ignored)
 * - dst_stage/access: dst_use_stage, dst_use_access
 * dependency chain:
 * src_use -> release op -> src_command done -> dst_command's wait stage start execute -> acquire
 * op
 * -> dst_use
 */
struct BarrierScope {
  Scope src_scope;
  Scope dst_scope;

  /**
   * @brief generate the barrier scope used to record release operation
   * @param src_scope the scope happen before release op
   */
  static auto release(Scope src_scope) -> BarrierScope {
    return {
      src_scope,
      Scope{ VK_PIPELINE_STAGE_NONE, VK_ACCESS_NONE },
    };
  }
  /**
   * @brief generate the barrier scope used to record acquire operation
   * @param dst_scope the scope happen after acquire op
   */
  static auto acquire(Scope dst_scope) -> BarrierScope {
    return {
      Scope{ VK_PIPELINE_STAGE_NONE, VK_ACCESS_NONE },
      dst_scope,
    };
  }
};

struct FamilyTransferInfo {
  uint32 src_family = VK_QUEUE_FAMILY_IGNORED;
  uint32 dst_family = VK_QUEUE_FAMILY_IGNORED;
};

void recordBufferBarrier(
  VkCommandBuffer    cmdbuf,
  VkBuffer           buffer,
  BarrierScope       barrier_scope,
  FamilyTransferInfo family_info
) {
  auto [src_scope, dst_scope] = barrier_scope;
  auto buffer_barrier = VkBufferMemoryBarrier2{
    .sType = VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER_2,
    .pNext = nullptr,
    .srcStageMask = src_scope.stage_mask,
    .srcAccessMask = src_scope.access_mask,
    .dstStageMask = dst_scope.stage_mask,
    .dstAccessMask = dst_scope.access_mask,
    .srcQueueFamilyIndex = family_info.src_family,
    .dstQueueFamilyIndex = family_info.dst_family,
    .buffer = buffer,
    .offset = 0,
    .size = VK_WHOLE_SIZE,
  };
  recordPipelineBarrier(cmdbuf, {}, { &buffer_barrier, 1 }, {});
}

struct LayoutTransitionInfo {
  VkImageLayout src_layout;
  VkImageLayout dst_layout;
};

auto stageMask2Str(VkPipelineStageFlags2 stage_mask) -> std::string {
  auto str_list = std::vector<std::string>{};
  for (auto i = 0; i < sizeof(VkPipelineStageFlagBits) * 8; ++i) {
    auto stage = static_cast<VkPipelineStageFlagBits>(1 << i);
    if (stage & stage_mask) {
      str_list.push_back(std::string{ refl::stageFlag(stage) } + " | ");
    }
  }
  if (str_list.empty()) {
    return std::string{ refl::stageFlag(VK_PIPELINE_STAGE_NONE) };
  } else {
    return views::join(str_list) | views::reverse | views::drop(3) | views::reverse |
           ranges::to<std::string>();
  }
}

auto accessMask2Str(VkAccessFlags2 access_mask) -> std::string {
  auto str_list = std::vector<std::string>{};
  for (auto i = 0; i < sizeof(VkAccessFlagBits) * 8; ++i) {
    auto access = static_cast<VkAccessFlagBits>(1 << i);
    if (access & access_mask) {
      str_list.push_back(std::string{ refl::accessFlag(access) } + " | ");
    }
  }
  if (str_list.empty()) {
    return std::string{ refl::accessFlag(VK_ACCESS_NONE) };
  } else {
    return views::join(str_list) | views::reverse | views::drop(3) | views::reverse |
           ranges::to<std::string>();
  }
}

auto scope2Str(Scope scope) -> std::string {
  return "{" + stageMask2Str(scope.stage_mask) + " / " + accessMask2Str(scope.access_mask) + "}";
}

void recordImageBarrier(
  VkCommandBuffer         cmdbuf,
  VkImage                 image,
  VkImageSubresourceRange subresource_range,
  LayoutTransitionInfo    layout_info,
  BarrierScope            barrier_scope,
  FamilyTransferInfo      family_info
) {
  if constexpr (false) {
    toy::debugf(
      toy::NoLocation{},
      "record image barrier:\n  image = {},\n  layout = {} -> {},\n  scope = {} -> {},\n  family = "
      "{} -> {}",
      reinterpret_cast<void*>(image),
      refl::imageLayout(layout_info.src_layout),
      refl::imageLayout(layout_info.dst_layout),
      scope2Str(barrier_scope.src_scope),
      scope2Str(barrier_scope.dst_scope),
      family_info.src_family,
      family_info.dst_family
    );
  }
  auto [src_scope, dst_scope] = barrier_scope;
  auto image_barrier = VkImageMemoryBarrier2{
    .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER_2,
    .pNext = nullptr,
    .srcStageMask = src_scope.stage_mask,
    .srcAccessMask = src_scope.access_mask,
    .dstStageMask = dst_scope.stage_mask,
    .dstAccessMask = dst_scope.access_mask,
    .oldLayout = layout_info.src_layout,
    .newLayout = layout_info.dst_layout,
    .srcQueueFamilyIndex = family_info.src_family,
    .dstQueueFamilyIndex = family_info.dst_family,
    .image = image,
    .subresourceRange = subresource_range,
  };
  recordPipelineBarrier(cmdbuf, {}, {}, { &image_barrier, 1 });
}

} // namespace rd::vk