export module vulkan.sync;

import "vulkan_config.h";
import vulkan.resource;
import vulkan.tool;
import vulkan.image;
import std;
import toy;

export namespace vk {

auto createSemaphore(VkDevice device) -> Semaphore {
  VkSemaphoreCreateInfo create_info{
    .sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO,

  };
  return Semaphore{ device, create_info };
}
auto createFence(VkDevice device, bool signaled) -> Fence {
  VkFenceCreateInfo create_info{
    .sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO,
  };
  if (signaled) {
    create_info.flags = VK_FENCE_CREATE_SIGNALED_BIT;
  }
  return Fence{ device, create_info };
}

void waitFence(VkDevice device, VkFence fence) {
  checkVkResult(
    vkWaitForFences(device, 1, &fence, VK_TRUE, std::numeric_limits<uint64_t>::max()), "wait fences"
  );
}

void resetFence(VkDevice device, VkFence fence) {
  checkVkResult(vkResetFences(device, 1, &fence), "reset fence");
}

/**
 * VK_SUCCESS: The fence specified by fence is signaled.
 * VK_NOT_READY: The fence specified by fence is unsignaled.
 * VK_ERROR_DEVICE_LOST: The device has been lost. See Lost Device.
 */
auto isFenceSignaled(VkDevice device, VkFence fence) -> bool {
  auto result = vkGetFenceStatus(device, fence);
  if (result == VK_SUCCESS) {
    return true;
  } else if (result == VK_NOT_READY) {
    return false;
  } else {
    vk::checkVkResult(result, "get fence status");
  }
  std::unreachable();
}

void recordPipelineBarrier(
  VkCommandBuffer                                       cmdbuf,
  std::pair<VkPipelineStageFlags, VkPipelineStageFlags> stage_mask,
  std::span<const VkMemoryBarrier>                      memory_barriers,
  std::span<const VkBufferMemoryBarrier>                buffer_barriers,
  std::span<const VkImageMemoryBarrier>                 image_barriers
) {
  vkCmdPipelineBarrier(
    cmdbuf,
    stage_mask.first,
    stage_mask.second,
    //  VK_DEPENDENCY_BY_REGION_BIT:
    //  实现可以分区域进行同步(前面写一部分，后面就可以先读一部分)
    VK_DEPENDENCY_BY_REGION_BIT,
    memory_barriers.size(),
    memory_barriers.data(),
    buffer_barriers.size(),
    buffer_barriers.data(),
    image_barriers.size(),
    image_barriers.data()
  );
};

/**
 * @brief just can define execution dependency, no memory dependency
 */
enum class CommonUse {
  NONE,
  ALL,
};

enum class ImageUse {
  UNDEFINED,
  COPY_DST,
  COPY_SRC,
  FRAGMENT_SAMPLER,
  COLOR_ATTACHMENT,
  DEPTH_STENCIL_ATTACHMENT,
  PRESENT, // only can convert to layout, no scope
};

enum class BufferUse {
  COPY_DST,
  VERTEX_BUFFER_DRAW,
  INDEX_BUFFER_DRAW,
};

struct Scope {
  VkPipelineStageFlags stage_mask;
  VkAccessFlags        access_mask;

  Scope() = default;

  Scope(VkPipelineStageFlags stage_mask, VkAccessFlags access_mask)
    : stage_mask(stage_mask), access_mask(access_mask) {}

  Scope(VkPipelineStageFlags stage_mask) : stage_mask(stage_mask), access_mask(0) {}

  Scope(CommonUse use, bool is_dst) {
    switch (use) {
    case CommonUse::NONE:
      stage_mask =
        is_dst ? VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT : VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
      break;
    case CommonUse::ALL:
      stage_mask =
        is_dst ? VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT : VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT;
      break;
    }
    access_mask = 0;
  }

  Scope(BufferUse use, bool is_dst) {
    switch (use) {
    case BufferUse::COPY_DST:
      stage_mask = VK_PIPELINE_STAGE_TRANSFER_BIT;
      access_mask = VK_ACCESS_TRANSFER_WRITE_BIT;
      break;
    case BufferUse::VERTEX_BUFFER_DRAW:
      stage_mask = VK_PIPELINE_STAGE_VERTEX_INPUT_BIT;
      access_mask = is_dst ? (VkAccessFlags)VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT : 0;
      break;
    case BufferUse::INDEX_BUFFER_DRAW:
      stage_mask = VK_PIPELINE_STAGE_VERTEX_INPUT_BIT;
      access_mask = is_dst ? (VkAccessFlags)VK_ACCESS_INDEX_READ_BIT : 0;
      break;
    }
  }

  Scope(ImageUse use, bool is_dst) {
    switch (use) {
    case ImageUse::UNDEFINED:
      toy::throwf(!is_dst, "the UNDEFINED image use must with is_dst = false");
      *this = Scope(CommonUse::NONE, is_dst);
      break;
    case ImageUse::COPY_DST:
      stage_mask = VK_PIPELINE_STAGE_TRANSFER_BIT;
      access_mask = VK_ACCESS_TRANSFER_WRITE_BIT;
      break;
    case ImageUse::COPY_SRC:
      stage_mask = VK_PIPELINE_STAGE_TRANSFER_BIT;
      access_mask = (is_dst ? (VkAccessFlags)VK_ACCESS_TRANSFER_READ_BIT : 0);
      break;
    case ImageUse::FRAGMENT_SAMPLER:
      stage_mask = VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;
      access_mask = is_dst ? (VkAccessFlags)VK_ACCESS_SHADER_READ_BIT : 0;
      break;
    case ImageUse::COLOR_ATTACHMENT:
      stage_mask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;
      access_mask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT |
                    (is_dst ? (VkAccessFlags)VK_ACCESS_COLOR_ATTACHMENT_READ_BIT : 0);
      break;
    case ImageUse::DEPTH_STENCIL_ATTACHMENT:
      stage_mask =
        VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT | VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT;
      access_mask = VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT |
                    (is_dst ? (VkAccessFlags)VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT : 0);
      break;
    default:
      toy::throwf("the image use {} can not convert to ScopeInfo", (int)use);
      std::unreachable();
    }
  }

  friend auto operator|(Scope a, Scope b) -> Scope {
    return {
      a.stage_mask | b.stage_mask,
      a.access_mask | b.access_mask,
    };
  }
  /**
   * @brief convert to execution dependency
   */
  auto exeDep() -> Scope& {
    access_mask = 0;
    return *this;
  }
};

auto getLayout(ImageUse use) -> VkImageLayout {
  switch (use) {
  case ImageUse::UNDEFINED:
    return VK_IMAGE_LAYOUT_UNDEFINED;
  case ImageUse::COPY_DST:
    return VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
  case ImageUse::COPY_SRC:
    return VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
  case ImageUse::FRAGMENT_SAMPLER:
    return VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
  case ImageUse::COLOR_ATTACHMENT:
    return VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;
  case ImageUse::DEPTH_STENCIL_ATTACHMENT:
    return VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;
  case ImageUse::PRESENT:
    return VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;
  default:
    toy::throwf("the image use {} can not convert to image layout", (int)use);
    std::unreachable();
  }
}

/**
 * @brief In case of ownership transfer that with src_use_stage/access and dst_use_stage/access
 * barrier in src family:
 * - src_stage/access: src_use_stage, src_use_access
 * - dst_stage/access: BOTTOM, 0 (by spec: dst_stage/access are ignored)
 * barrier in dst family:
 * - must wait semaphore, wait stage: TOP
 * - src_stage/access: TOP, 0 (by spec: src_stage/access are ignored)
 * - dst_stage/access: dst_use_stage, dst_use_access
 * dependency chain:
 * src_use -> release op -> src_command done -> dst_command's wait stage start execute -> acquire op
 * -> dst_use
 */

struct BarrierScope {
  Scope src_scope;
  Scope dst_scope;

  BarrierScope(Scope src_scope, Scope dst_scope) : src_scope(src_scope), dst_scope(dst_scope) {}

  static auto release(ImageUse use) -> BarrierScope {
    return {
      Scope{ use, false },
      Scope{ CommonUse::NONE, true },
    };
  }
  static auto release(BufferUse use) -> BarrierScope {
    return {
      Scope{ use, false },
      Scope{ CommonUse::NONE, true },
    };
  }
  /**
   * @brief no available operation
   */
  static auto release(CommonUse use) -> BarrierScope {
    return {
      Scope{ use, false },
      Scope{ CommonUse::NONE, true },
    };
  }
  static auto acquire(ImageUse use) -> BarrierScope {
    return {
      Scope{ CommonUse::NONE, false },
      Scope{ use, true },
    };
  }
  static auto acquire(BufferUse use) -> BarrierScope {
    return {
      Scope{ CommonUse::NONE, false },
      Scope{ use, true },
    };
  }
  /**
   * @brief no visible operation
   */
  static auto acquire(CommonUse use) -> BarrierScope {
    return {
      Scope{ CommonUse::NONE, false },
      Scope{ use, true },
    };
  }
};

struct FamilyTransferInfo {
  uint32_t src_family = VK_QUEUE_FAMILY_IGNORED;
  uint32_t dst_family = VK_QUEUE_FAMILY_IGNORED;
};

struct LayoutTransitionInfo {
  VkImageLayout src_layout;
  VkImageLayout dst_layout;

  LayoutTransitionInfo(VkImageLayout src_layout, VkImageLayout dst_layout)
    : src_layout(src_layout), dst_layout(dst_layout) {}

  LayoutTransitionInfo(ImageUse src_use, ImageUse dst_use) {
    src_layout = getLayout(src_use);
    dst_layout = getLayout(dst_use);
  }
};

void recordBufferBarrier(
  VkCommandBuffer    cmdbuf,
  VkBuffer           buffer,
  BarrierScope       barrier_scope,
  FamilyTransferInfo family_info
) {
  auto [src_scope, dst_scope] = barrier_scope;
  auto buffer_barrier = VkBufferMemoryBarrier{
    .sType = VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER,
    .pNext = nullptr,
    .srcAccessMask = src_scope.access_mask,
    .dstAccessMask = dst_scope.access_mask,
    .srcQueueFamilyIndex = family_info.src_family,
    .dstQueueFamilyIndex = family_info.dst_family,
    .buffer = buffer,
    .offset = 0,
    .size = VK_WHOLE_SIZE,
  };
  recordPipelineBarrier(
    cmdbuf, { src_scope.stage_mask, dst_scope.stage_mask }, {}, { &buffer_barrier, 1 }, {}
  );
}

void recordImageBarrier(
  VkCommandBuffer      cmdbuf,
  VkImage              image,
  ImageType            type,
  MipRange             mip_range,
  LayoutTransitionInfo layout_info,
  BarrierScope         barrier_scope,
  FamilyTransferInfo   family_info
) {
  auto [src_scope, dst_scope] = barrier_scope;
  auto image_barrier = VkImageMemoryBarrier{
    .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
    .pNext = nullptr,
    .srcAccessMask = src_scope.access_mask,
    .dstAccessMask = dst_scope.access_mask,
    .oldLayout = layout_info.src_layout,
    .newLayout = layout_info.dst_layout,
    .srcQueueFamilyIndex = family_info.src_family,
    .dstQueueFamilyIndex = family_info.dst_family,
    .image = image,
    .subresourceRange = getSubResourceRange(type, mip_range),
  };
  recordPipelineBarrier(
    cmdbuf, { src_scope.stage_mask, dst_scope.stage_mask }, {}, {}, { &image_barrier, 1 }
  );
}

} // namespace vk