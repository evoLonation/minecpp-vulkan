export module render.command;

import "vulkan_config.h";
import vulkan;
import std;
import toy;

import render.context;

export namespace render {

template <typename ResourceT, typename Derived>
class CommonPool;
template <typename VkHandle, typename Derived>
class CommonPool<vk::Resource<VkHandle>, Derived> {
private:
  std::vector<vk::Resource<VkHandle>> _resources;
  std::vector<VkHandle>               _resource_frees;

public:
  auto allocate() {
    auto handle = VkHandle{};
    if (_resource_frees.empty()) {
      _resources.push_back(Derived::_creator());
      handle = _resources.back().get();
    } else {
      handle = _resource_frees.back();
      _resource_frees.pop_back();
    }
    auto deleter = [&](VkHandle handle) { _resource_frees.push_back(handle); };
    return std::unique_ptr<std::remove_pointer_t<VkHandle>, decltype(deleter)>{ handle, deleter };
  }
};

class FencePool : public CommonPool<vk::Fence, FencePool> {
private:
  friend CommonPool<vk::Fence, FencePool>;
  static constexpr auto _creator = []() {
    return vk::createFence(Context::getInstance().device, false);
  };
};
class SemaphorePool : public CommonPool<vk::Semaphore, SemaphorePool> {
private:
  friend CommonPool<vk::Semaphore, SemaphorePool>;
  static constexpr auto _creator = []() {
    return vk::createSemaphore(Context::getInstance().device);
  };
};

class CmdbufPool {
private:
  vk::CommandPool                 _cmd_pool;
  static constexpr auto           _cmdbuf_allocate_n = 5;
  std::vector<vk::CommandBuffers> _cmdbufs;
  std::vector<VkCommandBuffer>    _cmdbuf_frees;

public:
  CmdbufPool() = default;
  CmdbufPool(Context::CommandContext& cmd_ctx) {
    _cmd_pool = vk::createCommandPool(Context::getInstance().device, cmd_ctx.family_index, true);
  }
  auto allocate() {
    auto handle = VkCommandBuffer{};
    if (_cmdbuf_frees.empty()) {
      _cmdbufs.emplace_back(
        vk::allocateCommandBuffers(Context::getInstance().device, _cmd_pool, _cmdbuf_allocate_n)
      );
      auto resources = _cmdbufs.back().get();
      [&]<size_t... indices>(std::index_sequence<indices...> index_seq) {
        (_cmdbuf_frees.emplace_back(resources[indices]), ...);
      }(std::make_index_sequence<_cmdbuf_allocate_n - 1>{});
      handle = resources[_cmdbuf_allocate_n - 1];
    } else {
      handle = _cmdbuf_frees.back();
      _cmdbuf_frees.pop_back();
    }
    auto deleter = [&](VkCommandBuffer handle) { _cmdbuf_frees.push_back(handle); };
    return std::unique_ptr<std::remove_pointer_t<VkCommandBuffer>, decltype(deleter)>{
      handle, std::move(deleter)
    };
  }
};

template <typename PoolT>
using PoolResource = toy::FuncRet<decltype(&PoolT::allocate)>;

template <typename T, typename R>
concept ResourcePool = requires(T t, R resource) { resource = t.allocate().get(); };
static_assert(ResourcePool<CmdbufPool, VkCommandBuffer>, "");
static_assert(ResourcePool<FencePool, VkFence>, "");
static_assert(ResourcePool<SemaphorePool, VkSemaphore>, "");

template <typename VkHandle>
class BorrowedHandle {
private:
  static inline auto borrow_deleter = [](bool* borrowed) { *borrowed = false; };
  static inline auto empty_deleter = [](auto* p) {};
  std::unique_ptr<bool, decltype(borrow_deleter)> _borrowed;

protected:
  std::unique_ptr<std::remove_pointer_t<VkHandle>, decltype(empty_deleter)> _handle;

public:
  BorrowedHandle() = default;
  BorrowedHandle(VkHandle handle, bool& borrowed) {
    borrowed = true;
    _borrowed.reset(&borrowed);
    _handle.reset(handle);
  }
  auto get() { return _handle.get(); }
};

class Fence : public BorrowedHandle<VkFence> {
public:
  using BorrowedHandle<VkFence>::BorrowedHandle;
  void wait() {
    if (_handle.get() == nullptr) {
      return;
    }
    vk::waitFence(Context::getInstance().device, _handle.get());
  }
  auto signaled() -> bool {
    if (_handle.get() == nullptr) {
      return false;
    }
    return vk::isFenceSignaled(Context::getInstance().device, _handle.get());
  }
};

class Semaphore : public BorrowedHandle<VkSemaphore> {
public:
  using BorrowedHandle<VkSemaphore>::BorrowedHandle;
};

class Waitable {
private:
  std::vector<Semaphore> _semas;

public:
  Waitable() = default;
  Waitable(std::vector<Semaphore> semas) : _semas(std::move(semas)) {}
  auto consume() -> Semaphore {
    if (_semas.empty()) {
      toy::throwf("The waitable has no semaphore!");
    }
    auto sema = std::move(_semas.back());
    _semas.pop_back();
    return sema;
  }
};

using WaitInfo = std::pair<Waitable&, VkPipelineStageFlags>;

class CommandExecutor : public toy::ProactiveSingleton<CommandExecutor> {
private:
  struct WorkingCmdbuf {
    PoolResource<CmdbufPool> cmdbuf;
    VkFence                  fence;
    std::vector<VkSemaphore> wait_semas;
    std::vector<VkSemaphore> signal_semas;
    WorkingCmdbuf(
      CmdbufPool&              pool,
      VkFence                  fence,
      std::vector<VkSemaphore> wait_semas,
      std::vector<VkSemaphore> signal_semas
    )
      : cmdbuf(pool.allocate()), fence(fence), wait_semas(std::move(wait_semas)),
        signal_semas(std::move(signal_semas)) {}
  };
  struct WorkingFence {
    PoolResource<FencePool> fence;

    bool borrowed;
    bool cmd_done;
    WorkingFence(FencePool& pool) : fence(pool.allocate()), borrowed(false), cmd_done(false) {}
  };
  struct WorkingSemaphore {
    PoolResource<SemaphorePool> sema;

    bool borrowed;
    bool signal_cmd_done;
    // if no wait, true
    bool wait_cmd_done;
    WorkingSemaphore(SemaphorePool& pool)
      : sema(pool.allocate()), borrowed(false), signal_cmd_done(false), wait_cmd_done(true) {}
  };
  using WorkingCmdbufs = std::map<VkCommandBuffer, WorkingCmdbuf>;
  using WorkingFences = std::map<VkFence, WorkingFence>;
  using WorkingSemaphores = std::map<VkSemaphore, WorkingSemaphore>;

  auto addWorkingFence() -> Fence {
    auto  working_ = WorkingFence{ _fence_pool };
    auto& working =
      _working_fences.emplace(working_.fence.get(), std::move(working_)).first->second;
    return Fence{ working.fence.get(), working.borrowed };
  }

  auto addWorkingSemas(int sema_n) -> std::vector<Semaphore> {
    auto borrowed_semas = std::vector<Semaphore>{};
    while (sema_n--) {
      auto  working_ = WorkingSemaphore{ _sema_pool };
      auto& working =
        _working_semas.emplace(working_.sema.get(), std::move(working_)).first->second;
      borrowed_semas.emplace_back(working.sema.get(), working.borrowed);
    }
    return std::move(borrowed_semas);
  }

  auto addWorkingCmdbuf(
    CmdbufPool&              cmdbuf_pool,
    WorkingCmdbufs&          working_cmdbufs,
    VkFence                  fence,
    std::vector<VkSemaphore> wait_semas,
    std::vector<VkSemaphore> signal_semas
  ) -> VkCommandBuffer {
    auto cmd_working =
      WorkingCmdbuf{ cmdbuf_pool, fence, std::move(wait_semas), std::move(signal_semas) };
    auto cmdbuf = cmd_working.cmdbuf.get();
    working_cmdbufs.emplace(cmd_working.cmdbuf.get(), std::move(cmd_working));
    return cmdbuf;
  }

public:
  enum class Family { TRANSFER, GRAPHICS };

private:
  auto getFamilyContext(Family family) -> std::tuple<CmdbufPool&, VkQueue, WorkingCmdbufs&> {
    switch (family) {
    case Family::GRAPHICS:
      return { _graphic_pool, Context::getInstance().graphic_ctx.queue, _working_graphic_cmdbufs };
    case Family::TRANSFER:
      return { _transfer_pool,
               Context::getInstance().transfer_ctx.queue,
               _working_transfer_cmdbufs };
    }
  }

public:
  auto submit(
    Family family, vk::Recorder auto&& recorder, std::span<WaitInfo const> wait_infos, int signal_n
  ) -> std::pair<Fence, Waitable> {
    auto guard = std::lock_guard<std::mutex>{ _mutex };
    auto [cmdbuf_pool, queue, working_cmdbufs] = getFamilyContext(family);
    auto borrowed_fence = addWorkingFence();
    auto borrowed_semas = addWorkingSemas(signal_n);
    auto wait_borroweds = wait_infos |
                          views::transform([](auto info) { return info.first.consume(); }) |
                          ranges::to<std::vector>();
    auto wait_semas = wait_borroweds |
                      views::transform([](auto& borrowed) { return borrowed.get(); }) |
                      ranges::to<std::vector>();
    auto signal_semas = borrowed_semas |
                        views::transform([](auto& borrowed) { return borrowed.get(); }) |
                        ranges::to<std::vector>();
    for (auto sema : wait_semas) {
      _working_semas.at(sema).wait_cmd_done = false;
    }
    auto cmdbuf = addWorkingCmdbuf(
      cmdbuf_pool,
      working_cmdbufs,
      borrowed_fence.get(),
      std::move(wait_semas),
      std::move(signal_semas)
    );
    auto wait_stages = wait_infos | views::transform([](auto info) { return info.second; }) |
                       ranges::to<std::vector>();
    auto wait_vk_infos = views::zip(wait_semas, wait_stages) | ranges::to<std::vector>();
    vk::recordAndSubmit(cmdbuf, queue, recorder, wait_vk_infos, signal_semas, borrowed_fence.get());
    return std::pair{ std::move(borrowed_fence), std::move(borrowed_semas) };
  }

public:
  auto submit(
    Family                        family,
    vk::Recorder auto&&           recorder,
    std::span<const vk::WaitInfo> wait_infos,
    std::span<const VkSemaphore>  signal_semas
  ) -> Fence {
    auto guard = std::lock_guard<std::mutex>{ _mutex };
    auto [cmdbuf_pool, queue, working_cmdbufs] = getFamilyContext(family);
    auto borrowed_fence = addWorkingFence();
    auto cmdbuf = addWorkingCmdbuf(cmdbuf_pool, working_cmdbufs, borrowed_fence.get(), {}, {});
    vk::recordAndSubmit(cmdbuf, queue, recorder, wait_infos, signal_semas, borrowed_fence.get());
    return std::move(borrowed_fence);
  }

public:
  void collect() {
    auto guard = std::lock_guard<std::mutex>{ _mutex };
    // DO NOT erase element in range for iteration, if need erase, do like this
    auto cmdbuf_collect = [&](WorkingCmdbufs& working_cmdbufs, CmdbufPool& cmdbuf_pool) {
      for (auto iter = working_cmdbufs.begin(); iter != working_cmdbufs.end();) {
        auto& info = iter->second;
        if (vk::isFenceSignaled(Context::getInstance().device, info.fence)) {
          _working_fences.at(info.fence).cmd_done = true;
          for (auto sema : info.signal_semas) {
            _working_semas.at(sema).signal_cmd_done = true;
          }
          for (auto sema : info.wait_semas) {
            _working_semas.at(sema).wait_cmd_done = true;
          }
          working_cmdbufs.erase(iter++);
        } else {
          iter++;
        }
      }
    };
    cmdbuf_collect(_working_graphic_cmdbufs, _graphic_pool);
    cmdbuf_collect(_working_transfer_cmdbufs, _transfer_pool);
    for (auto iter = _working_fences.begin(); iter != _working_fences.end();) {
      auto& info = iter->second;
      if (!info.borrowed && info.cmd_done) {
        vk::resetFence(Context::getInstance().device, info.fence.get());
        _working_fences.erase(iter++);
      } else {
        iter++;
      }
    }
    for (auto iter = _working_semas.begin(); iter != _working_semas.end();) {
      auto& info = iter->second;
      if (!info.borrowed && info.signal_cmd_done && info.wait_cmd_done) {
        _working_semas.erase(iter++);
      } else {
        iter++;
      }
    }
  }

  CmdbufPool    _graphic_pool;
  CmdbufPool    _transfer_pool;
  FencePool     _fence_pool;
  SemaphorePool _sema_pool;

  WorkingCmdbufs    _working_graphic_cmdbufs;
  WorkingCmdbufs    _working_transfer_cmdbufs;
  WorkingFences     _working_fences;
  WorkingSemaphores _working_semas;

  std::mutex  _mutex;
  std::thread _thread;
  bool        _task_done;

public:
  void task() {
    while (
      !(_task_done && _working_graphic_cmdbufs.empty() && _working_transfer_cmdbufs.empty() &&
        _working_fences.empty() && _working_semas.empty())
    ) {
      using namespace std::chrono_literals;
      std::this_thread::sleep_for(20ms);
      collect();
    }
  }

  CommandExecutor() {
    auto& ctx = Context::getInstance();
    _graphic_pool = CmdbufPool{ ctx.graphic_ctx };
    _transfer_pool = CmdbufPool{ ctx.transfer_ctx };
    _thread = std::thread{ &CommandExecutor::task, this };
    _task_done = false;
  }
  ~CommandExecutor() {
    _task_done = true;
    _thread.join();
  }
};

} // namespace render